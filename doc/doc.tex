\documentclass[11pt]{article}
%prepared in AMSLaTeX, under LaTeX2e
\addtolength{\oddsidemargin}{-.75in} 
\addtolength{\evensidemargin}{-.75in}
\addtolength{\topmargin}{-.6in}
\addtolength{\textwidth}{1.4in}
\addtolength{\textheight}{1.3in}

\renewcommand{\baselinestretch}{1.075}

\usepackage{verbatim,fancyvrb}

\usepackage{palatino,amsmath,amssymb,amsthm}

\usepackage{tikz}
\usetikzlibrary{arrows.meta}

\newtheorem*{thm}{Theorem}
\newtheorem*{defn}{Definition}
\newtheorem*{example}{Example}
\newtheorem*{problem}{Problem}
\newtheorem*{remark}{Remark}

\newcommand{\mtt}{\texttt}
\usepackage{alltt,xspace}

%\usepackage[final]{graphicx}

\usepackage[pdftex, colorlinks=true, plainpages=false, linkcolor=blue, citecolor=red, urlcolor=blue]{hyperref}

% macros
\newcommand{\bc}{\mathbf{c}}
\newcommand{\br}{\mathbf{r}}
\newcommand{\bv}{\mathbf{v}}
\newcommand{\bx}{\mathbf{x}}
\newcommand{\by}{\mathbf{y}}

\newcommand{\CC}{\mathbb{C}}
\newcommand{\RR}{\mathbb{R}}
\newcommand{\ZZ}{\mathbb{Z}}

\newcommand{\eps}{\epsilon}
\newcommand{\grad}{\nabla}
\newcommand{\lam}{\lambda}
\newcommand{\lap}{\triangle}

\newcommand{\ip}[2]{\ensuremath{\left<#1,#2\right>}}

%\renewcommand{\det}{\operatorname{det}}
\newcommand{\onull}{\operatorname{null}}
\newcommand{\rank}{\operatorname{rank}}
\newcommand{\range}{\operatorname{range}}

\newcommand{\prob}[1]{\bigskip\noindent\textbf{#1.}\quad }
\newcommand{\exer}[2]{\prob{Exercise #2 in Lecture #1}}

\newcommand{\pts}[1]{(\emph{#1 pts}) }
\newcommand{\epart}[1]{\medskip\noindent\textbf{(#1)}\quad }
\newcommand{\ppart}[1]{\,\textbf{(#1)}\quad }

\newcommand{\Julia}{\textsc{Julia}\xspace}
\newcommand{\Matlab}{\textsc{Matlab}\xspace}
\newcommand{\Octave}{\textsc{Octave}\xspace}
\newcommand{\Python}{\textsc{Python}\xspace}

\DefineVerbatimEnvironment{mVerb}{Verbatim}{numbersep=2mm,
frame=lines,framerule=0.1mm,framesep=2mm,xleftmargin=4mm,fontsize=\footnotesize}

\newcommand{\ema}{\emach}
\newcommand{\emach}{\eps_{\!_{\text{m}}}}

\title{POPDIP: a POsitive-variables \\ Primal-Dual Interior Point optimization method}
\author{Ed Bueler}
\date{\today}

\begin{document}
\maketitle

\begin{abstract}
The algorithm documented here is a modest modification of the Newton-type primal-dual interior point algorithm in \cite{GrivaNashSofer2009}, namely Algorithm 16.1 in section 16.7.  This version minimizes a smooth nonlinear function subject to the constraints that all the variables are nonnegative, plus linear equality constraints:
\begin{equation}
\begin{matrix}
\text{minimize} \qquad   & f(x) \\
\text{subject to} \qquad & A x = b \\
                         & x \ge 0
\end{matrix} \label{eq:abstractproblem}
\end{equation}

The algorithm can be used as an interior-point method for linear programming in the case where $f(x)=c^\top x$.  However, this is a specialized algorithm for nonnegativity constraints $x\ge 0$, and it is not suitable for general inequality constraints of the form ``$g_i(x)\ge 0$.''

These short notes are not research!  We consider a special case of a well-known algorithm.  Furthermore ``POPDIP'' is just a name I made up; it is not in common use. However, this class of algorithms is new to me so I am documenting it fully.
\end{abstract}

\thispagestyle{empty}

\bigskip
\subsection*{Introduction}

Consider first a nonlinear optimization problem with only nonnegativity (informally: positivity) constraints on the variables:
\begin{equation}
\begin{matrix}
\text{minimize} \qquad & f(x) \\
\text{subject to} \qquad & x \ge 0
\end{matrix} \label{eq:posproblem}
\end{equation}
The next section will address the more general problem including linear equality constraints.

As usual, ``$x\ge 0$'' in \eqref{eq:posproblem} means that each entry of $x\in\RR^n$ is nonnegative.  The feasible set for \eqref{eq:posproblem} is the convex and closed set $S = \{x\in \RR^n\,:\,x\ge 0\}$ with interior $S^\circ = \{x\in \RR^n\,:\,x > 0\}$.  Here $f:S \to \RR$ is a continuous and smooth function, but for greater simplicity of the presentation we will assume that $f$ is defined on all of $\RR^n$.

One can start the derivation by considering a logarithmic barrier function \cite[section 16.2]{GrivaNashSofer2009}.  Let $\mu>0$ be a (temporarily) fixed constant.  If $x\in S^\circ$ then the following function is well-defined:
\begin{equation}
\beta_\mu(x) = f(x) - \mu \sum_{i=1}^n \ln x_i \label{eq:posbarrierfunction}
\end{equation}
Let $\{e_1,\dots,e_n\}$ be the standard basis of $\RR^n$.  The first-order necessary condition for the \emph{unconstrained} problem of minimizing $\beta_\mu$, namely $\grad \beta_\mu(x)=0$ for $x \in S^\circ$, is
\begin{equation}
\grad f(x) - \mu \sum_{i=1}^n \frac{1}{x_i} e_i = 0 \label{eq:posfirstorderbarrier}
\end{equation}

Conditions \eqref{eq:posfirstorderbarrier} can be reformulated by defining additional variables
    $$\lambda_i = \frac{\mu}{x_i}$$
so that $\lambda\in\RR^n$.  Note that $\lambda>0$ if and only if $x>0$ because $\lambda_i x_i = \mu > 0$.  Then \eqref{eq:posfirstorderbarrier}, plus feasibility for $x$, is precisely equivalent to the following nonlinear system of equations and inequalities:
\begin{align}
\grad f(x) - \lambda &= 0 \label{eq:posfirstordersystem} \\
\lambda_i x_i &= \mu, \qquad i=1,\dots,n \notag \\
x &\ge 0 \notag \\
\lambda &\ge 0 \notag
\end{align}

The feasible set for $x$ and for $\lambda$ is the same, namely $S \subset \RR^n$.  Because of the second condition in \eqref{eq:posfirstordersystem}, both $x$ and $\lambda$ are positive and thus in the interior $S^\circ$.  By contrast, for the general primal-dual interior point method, specifically Algorithm 16.1 in \cite[section 16.7]{GrivaNashSofer2009}, the feasible set for the primal variable $x$ is different from the dual feasible set for $\lambda$.

The first condition in \eqref{eq:posfirstordersystem} can be written using a Lagrangian function for \eqref{eq:posproblem}, namely
\begin{equation}
\mathcal{L}(x,\lambda) = f(x) - \sum_{i=1}^n \lambda_i x_i,  \label{eq:posLagrangian}
\end{equation}
in which case it states that $\grad_x \mathcal{L}(x,\lambda)=0$.  In fact, the KKT conditions \cite[sections 14.4, 14.5]{GrivaNashSofer2009} of \eqref{eq:posproblem} are nearly the same as \eqref{eq:posfirstordersystem} but with the second equation replaced by a condition of complementary slackness,
\begin{align}
\grad f(x) - \lambda &= 0 \label{eq:posKKT} \\
\lambda_i x_i &= 0, \qquad i=1,\dots,n \notag \\
x &\ge 0 \notag \\
\lambda &\ge 0 \notag
\end{align}
Thus the barrier method which generated system \eqref{eq:posfirstordersystem} modifies KKT conditions \eqref{eq:posKKT} by changing complementary slackness into a connection between the primal and dual variables.  (Their product is set to a positive constant.)  Thus system \eqref{eq:posfirstordersystem} describes a solution which is different from the KKT conditions for \eqref{eq:posproblem}.

The first KKT condition in \eqref{eq:posKKT} allows $\lambda$ to be eliminated if desired, i.e.~$\lambda = \grad f(x)$.  Writing the conditions without these dual variables gives a \emph{nonlinear complementary problem} (NCP) \cite{FacchineiPang2007},\footnote{NCP formulations also appear in problems which are not optimizations, rather variational inequalities \cite{BensonMunson2006,Bueler2016}.}
\begin{equation}
x \ge 0, \qquad \grad f(x) \ge 0, \qquad x_i (\grad f(x))_i = 0.  \label{eq:posNCP}
\end{equation}
Thus we may regard POPDIP as solving the barrier-modified NCP corresponding to \eqref{eq:posbarrierfunction}:
    $$x \ge 0, \qquad \grad f(x) \ge 0, \qquad x_i (\grad f(x))_i = \mu.$$
However, the method achieves quadratic convergence substantially because it updates both the primal variables $x$ and the dual variables $\lambda$, so stating the algorithm or the original KKT conditions as an NCP, suppressing the dual variables, is not beneficial.


\subsection*{General problem solved by POPDIP}

Suppose from now on that $f:\RR^n \to \RR$ is twice continuously-differentiable.  Let $A\in\RR^{m\times n}$, $m\le n$, be a full rank matrix, and suppose $b\in\RR^m$.  The POPDIP algorithm in the next section solves the problem
\begin{equation}
\begin{matrix}
\text{minimize} \qquad   & f(x) \\
\text{subject to} \qquad & A x = b \\
                         & x \ge 0
\end{matrix} \label{eq:problem}
\end{equation}
Observe that the constraints are in standard form for linear programming (LP) problems \cite[chapter 4]{GrivaNashSofer2009}.  The feasible set is
\begin{equation}
S = \{Ax=b \text{ and } x\ge 0\} \subset \RR^n.  \label{eq:feasible}
\end{equation}
If $f(x)=c^\top x$ for some fixed $c\in\RR^n$ then \eqref{eq:problem} is an LP problem in standard form.

FIXME

\subsection*{Algorithm design}

Algorithm 16.1 \cite{GrivaNashSofer2009} applies to \eqref{minproblem}.  The POPDIP algorithm proposed below is the simplification for $g_i(x)=x_i$.  All such primal-dual interior point algorithms \cite{NocedalWright2006} compute approximate solutions to systems like \eqref{firstordersystem} for a sequence $\{\mu_k>0\}$ going to zero.  The limit where $\mu=0$, never achieved because the algorithm is terminated after a finite number of steps, solves the KKT conditions \eqref{KKT}.

Each step of the algorithm is a Newton step for the equalities in \eqref{firstordersystem}, namely
\begin{align}
\grad f(x) - \lambda &= 0 \label{equalitysystem} \\
\lambda_i x_i &= \mu_k, \qquad i=1,\dots,n. \notag
\end{align}
The step updates both $x$ and $\lambda$ using the linearization of these equations.

Because of the second equation, \eqref{equalitysystem} is always a nonlinear system.  However, if $f$ is quadratic then the first equation is linear.

To describe the Newton step let $x=x_k+\Delta x$ and $\lambda=\lambda_k+\Delta\lambda$.  We assume that the current iterate $(x_k,\lambda_k)$ does not solve \eqref{equalitysystem}.  The unknowns in the Newton step form the search direction $p=(\Delta x,\Delta \lambda)$.  Substituting into \eqref{equalitysystem} and expanding to first order gives
\begin{align}
\grad f(x_k) + \grad^2 f(x_k) \Delta x - \lambda_k - \Delta \lambda &= 0 \label{prenewtonstep} \\
(\lambda_k)_i (x_k)_i + (x_k)_i (\Delta\lambda)_i + (\lambda_k)_i (\Delta x)_i &= \mu_k, \qquad i=1,\dots,n \notag
\end{align}
Rearranging as a linear block system for the search direction, and suppressing the current-iterate subscript, we get step equations
\begin{equation}
\begin{bmatrix}
\grad^2 f(x) & - I \\
\Lambda & X
\end{bmatrix}
\begin{bmatrix}
\Delta x \\
\Delta \lambda
\end{bmatrix}
=
\begin{bmatrix}
-\grad f(x) + \lambda \\
-\Lambda x + \mu_k e
\end{bmatrix}
 \label{newtonstep}
\end{equation}
Here $I$ is the $n\times n$ identity matrix and the other notation is as follows:
    $$\Lambda = \begin{bmatrix} \lambda_1 & & \\ & \ddots & \\ & & \lambda_n \end{bmatrix}, \qquad X = \begin{bmatrix} x_1 & & \\ & \ddots & \\ & & x_n \end{bmatrix}, \qquad e = \begin{bmatrix} 1 \\ \vdots \\ 1 \end{bmatrix}.$$

Given a solution of \eqref{newtonstep} the update formulas are
\begin{align*}
x_{k+1} &= x_k + \alpha \Delta x \\
\lambda_{k+1} &= \lambda_k + \alpha \Delta \lambda
\end{align*}
A single maximum step size $\alpha$ for both the primal and dual variables is determined by a condition of (strict) positivity for both $x_{k+1}$ and $\lambda_{k+1}$ \cite{NocedalWright2006}.  (A ratio test suffices to keep $x$ feasible, in common with how the slack variables are limited in a general primal-dual interior point method \cite[subsection 16.7.2]{GrivaNashSofer2009}.  Back-tracking is not needed to maintain feasibility of the primal variables because of the linearity of the constraint functions in \eqref{minproblem}, namely $g_i(x)=x_i$.)  Because this is a Newton search one uses $\alpha=1$ for the largest allowed step.  Note we use $p=(\Delta x,\Delta \lambda) \in \RR^{2n}$ as a search direction.

The optimality test is the same as in Algorithm 16.1 \cite{GrivaNashSofer2009}.  It uses the merit function
\begin{equation}
    \nu(x,\lambda) = \max\{\|\grad f(x)-\lambda\|,\|\Lambda x\|\}  \label{merit}
\end{equation}
where $\|\cdot\|$ denotes the usual $L^2$ norm on $\RR^n$.  Note that once $\mu_k\to 0$ we have $\nu(x_*,\lambda_*) = 0$ for the exact optimum, but when $\mu_k \ne 0$ then the exact solution of \eqref{equalitysystem} does not make $\nu(x,\lambda)$ zero.  In fact $\nu(x_*,\lambda_*) = \sqrt{n}\, \mu_k$ for the exact solution of \eqref{equalitysystem}; if the merit function value $\nu(x_k,\lambda_k)$ is close to $\sqrt{n}\, \mu_k$ then we should decrease $\mu_k$ more rapidly.

Subsection 16.7.2 of \cite{GrivaNashSofer2009} describes how Algorithm 16.1 should be modified so that, by Theorem 16.17, the algorithm will exhibit the local quadratic convergence.\footnote{One would want this property for a Newton-type algorithm, but quadratic convergence is much harder to achieve in a constrained problem.  Thus I am interested in this algorithm!}  They describe how the general inequality constraints should be augmented by slack (excess) variables which have simple nonnegativity constraints, but in our case the constraints are already of that type.\footnote{The general replacement ``$g_i(x)\ge 0$'' by ``$g_i(x) - s_i =0$, $s_i\ge 0$'' would be, in our case, the replacement ``$x_i\ge 0$'' by ``$x_i-s_i=0$, $s_i\ge 0$.''  Clearly this is a meaningless renaming of the existing variables.}  However, Theorem 16.17 also uses a specific barrier parameter update for $\mu_k$ and a specific parameter choice for $\kappa$ in the ratio test.  In our case these are equations
\begin{align*}
\mu_k &= \min\{\theta \nu(x_k,\lambda_k),\nu(x_k,\lambda_k)^2\}, \\
\kappa &= \max\{\bar\kappa,1-\nu(x_k,\lambda_k)\},
\end{align*}
for parameters $0<\theta<1$ and $0<\bar\kappa<1$.  We choose these parameters based on the minimal hints in Example 16.16 on pages 643--644.

The method by which the initial dual variables are determined (below) is a somewhat ad hoc construction for which I have no reference.  This issue of initialization is discussed in \cite{Gertzetal2004}.


\subsection*{Algorithm}

We can now present a pseudocode for our algorithm.

\bigskip
\noindent \textsc{Algorithm POPDIP.}
\begin{quote}
\begin{itemize}
\item[\emph{inputs}]  primal initial values $x_0$ such that $x_0 > 0$
\item[]  smooth function $f$ returning $f(x)$, $\grad f(x)$, and $\grad^2 f(x)$
\item[\emph{parameters}]  $0<\text{\texttt{tol}}$ [default $\text{\texttt{tol}}=10^{-4}$]
\item[]  $\text{\texttt{maxiters}}>0$ [default $\text{\texttt{maxiters}}=200$]
\item[]  $0<\theta<1$ [default $\theta=0.1$]
\item[]  $0<\bar\kappa<1$ [default $\bar\kappa=0.9$]
\item[\emph{output}]  an estimate $(x_k,\lambda_k)$ of the solution
\item  determine initial dual variables:
    \renewcommand{\labelenumi}{(\roman{enumi})}
    \begin{enumerate}
    \item $y_0 = \grad f(x_0)$
    \item if $y_0 \le 0$ then $\mu_0=1$; otherwise $\mu_0$ is average of those products $(x_0)_i (y_0)i$ where $(y_0)_i > 0$
    \item $(\lambda_0)_i = \mu_0 / (x_0)_i$ for $i=1,\dots,n$
    \end{enumerate}
\item  for $k=0,1,2,\dots,\text{\texttt{maxiters}}-1$
    \renewcommand{\labelenumi}{(\roman{enumi})}
    \begin{enumerate}
    \item optimality test: if $\nu(x_k,\lambda_k)<\text{\texttt{tol}}$ then stop
    \item barrier parameter: $\mu_k = \min\{\theta \nu(x_k,\lambda_k),\nu(x_k,\lambda_k)^2\}$
    \item compute Newton step by solving this system for $(\Delta x,\Delta \lambda)$:
    $$\begin{bmatrix}
\grad^2 f(x_k) & - I \\
\Lambda_k & X_k
\end{bmatrix}
\begin{bmatrix}
\Delta x \\
\Delta \lambda
\end{bmatrix}
=
\begin{bmatrix}
-\grad f(x_k) + \lambda_k \\
-\Lambda_k x_k + \mu_k e
\end{bmatrix}$$
    \item ratio test for step sizes to keep $x_{k+1},\lambda_{k+1}$ positive:
\begin{align*}
\kappa &= \max\{\bar\kappa,1-\nu(x_k,\lambda_k)\} \\
\alpha &= \min_{1\le i\le n} \left\{1, \,-\kappa \frac{(x_k)_i}{(\Delta x)_i} \,:\, (\Delta x)_i < 0, \,-\kappa \frac{(\lambda_k)_i}{(\Delta \lambda)_i} \,:\, (\Delta \lambda)_i < 0\right\}
\end{align*}
    \item the update:
\begin{align*}
x_{k+1} &= x_k + \alpha \Delta x \\
\lambda_{k+1} &= \lambda_k + \alpha \Delta \lambda
\end{align*}
    \end{enumerate}
\end{itemize}
\end{quote}

This algorithm is implemented by a \Matlab code with signature

\medskip
\noindent \mbox{\texttt{function [xk,lamk,xklist,lamklist] = popdip(x0,f,tol,maxiters,theta,kappabar)}}

\medskip
\noindent Only inputs \texttt{x0,f} are required.  The parameters have the default values listed above.  If the outputs \texttt{xklist} and \texttt{lamklist} are not requested then they are not saved.

Download the code at
\begin{center}
    \href{http://bueler.github.io/M661F18/matlab/popdip.m}{\texttt{bueler.github.io/M661F18/matlab/popdip.m}}
\end{center}


\subsection*{Example 1}

We first try an easy 2D test problem in \href{http://bueler.github.io/M661F18/matlab/testpopdip.m}{\texttt{testpopdip.m}}:
\begin{equation}
\begin{matrix}
\text{minimize} \qquad & f(x) = \frac{1}{2} (x_1-1)^2 + \frac{1}{2} (x_2+1)^2 \\
\text{subject to} \qquad & x \ge 0
\end{matrix} \label{testoneproblem}
\end{equation}
For this objective function $f$ the unconstrained minimum is the infeasible point $\hat x =(1,-1)^\top$.  A sketch shows that the exact solution of the constrained problem is $x_*=(1,0)^\top$.  Running the code with the given initial iterate $x_0=(2,2)^\top$ and \texttt{tol} $=10^{-14}$, and otherwise using the default parameters in POPDIP, gives
\begin{Verbatim}[fontsize=\small]
>> testpopdip([2 2]',1.0e-14)
  1:    2.000000000000000    2.000000000000000
  2:    1.641421356237309    0.641421356237310
  3:    1.245446520462486    0.245446520462486
  4:    1.069404818969903    0.069404818969903
  5:    1.013447008853577    0.013447008853577
  6:    1.000537794151783    0.000537794151783
  7:    1.000000867357066    0.000000867357066
  8:    1.000000000002257    0.000000000002257
  9:    1.000000000000000    0.000000000000000
\end{Verbatim}
The printed columns are $(x_k)_1$ and $(x_k)_2$.  Note the apparent quadratic, or at least strongly superlinear, convergence.  The iterates $x_k$ are graphed in the following figure.

\bigskip
\begin{center}
\includegraphics[width=0.6\textwidth]{testpopdip}
\end{center}


\subsection*{Example 2}

FIXME obstacle problem in 1D

\begin{equation}
    f[u] = \int_0^1 \frac{1}{2} |u'(x)|^2 - q(x) u(x)\,dx \label{obstaclefunctional}
\end{equation}

$\Delta x = 1 / (n+1)$
\begin{equation}
    f(u) = \Delta x \sum_{i=0}^n \left(\frac{1}{2} \left(\frac{u_{i+1}-u_i}{\Delta x}\right)^2 - q(x_{i+1/2}) \frac{u_i + u_{i+1}}{2}\right) \label{obstacleobjective}
\end{equation}
where $u_0=0$ and $u_{n+1}=0$ when they appear

gradient components for $i=1,\dots,n$
\begin{equation}
\grad f(u)_i = \frac{1}{\Delta x} \left\{\begin{matrix}
2 u_1 - u_2 & (i=1) \\
-u_{i-1} + 2 u_i - u_{i+1} & (1<i<n) \\
-u_{n-1} + 2 u_n & (i=n) \\
\end{matrix} \right\} - \frac{\Delta x}{2} (q(x_{i-1/2}) + q(x_{i+1/2}))
\end{equation}

Hessian matrix
\begin{equation}
\grad^2 f(u) = \frac{1}{\Delta x} \begin{bmatrix}
2  & -1 &    &    \\
-1 &  2 & -1 &    \\
   &    & \ddots &\\
   &    & -1 &  2
\end{bmatrix}
\end{equation}

\subsection*{Possible improvements}

We may consider possible improvements of our algorithm.  First, in Algorithm 16.1 the computation of the Newton search direction is followed by separate line searches in $x$ and in $\lambda$.  These line searches only maintain nonnegativity and they do not seek sufficient decrease of $f(x)$; they only use ratio tests.  Secondly, equation \eqref{newtonstep} can be symmetrized by multiplying the second half of the equations by $-\Lambda^{-1}$:
\begin{equation}
\begin{bmatrix}
\grad^2 f(x) & - I \\
-I & - \Lambda^{-1} X
\end{bmatrix}
\begin{bmatrix}
\Delta x \\
\Delta \lambda
\end{bmatrix}
=
\begin{bmatrix}
-\grad f(x) + \lambda \\
x - \mu_k \Lambda^{-1} e
\end{bmatrix}
 \label{symmnewtonstep}
\end{equation}

FIXME further simplify into system of $n$ equations for $\lambda$ only

These facts suggests two possible changes:
\begin{enumerate}
\item Back-tracking line search is appropriate as a globalization even for unconstrained optimization.  Thus there must be cases where it is appropriate for problem \eqref{minproblem} as well.  Once the ratio tests are applied, further back-tracking could be used based on sufficient decrease.  Compare the modified back-tracking line searches in \cite{BensonMunson2006}.
\item One can replace linear system \eqref{newtonstep} with symmetrized system \eqref{symmnewtonstep}.
\end{enumerate}
Determining if these are actual improvements would require testing which we have not done.


%\subsection*{Application to example problem (\texttt{glacier}).}
%FIXME a primal-dual interior point method for a glacier problem appears in \cite{Calvoetal2003}

\medskip

\bibliography{doc}
\bibliographystyle{siam}

\end{document}

